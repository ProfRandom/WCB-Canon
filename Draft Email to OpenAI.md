**Subject:** Feedback: Workflow for Canonical Worldmaking Research with GPT

Hello OpenAI Team,

I wanted to share a concrete workflow that I’ve been developing with GPT, because it both highlights how powerful your models already are and where I feel friction that limits their full potential.

I’m working on a long-term project called **WCB (Worldmaking: Crafting and Building)** — essentially a quasiscientific framework for designing worlds, with a living glossary and a compendium of abstracts. GPT has become my indispensable collaborator in this, helping me:

- Generate and refine glossary entries, staging them before release into a master file.
    
- Write abstracts for each source file, then consolidate them into a Canon_Abstracts.md.
    
- **Compose new content and cross-check it against canon** to ensure consistency and avoid contradictions.
    
- **Double-check my math and scripts, teach me new techniques (mathematics, programming, Git)**, and act as an on-demand tutor as well as co-author.
    
- Stage, bump, and tag glossary versions in sync with Git.
    

This has turned GPT into something like a **partner and co-writer** rather than a mere assistant. In fact, this very email was drafted in collaboration with GPT, using the same workflow I’m describing here.

**Pain Points:**

- I have to constantly re-upload files (glossary, abstracts, source notes) so GPT can see the latest versions.
    
- GPT can’t maintain persistent access to my file tree (e.g. a Dropbox or GitHub repo), so we have to hack around with uploads and staging.
    
- Model “memory” works for terms, but not for synchronized documents, so I can’t just say “check the glossary and abstracts compendium” unless I’ve re-provided them.
    
- **Threads slow down and eventually degrade in performance**; this forces me to abandon long-lived threads and “re-educate” GPT in a new one, breaking continuity. This is a major _pain point_ because my project depends on stable, consistent context over time.
    

**A positive note:** Since I’m on a Business Plan and working within a Project, GPT _does_ maintain a very consistent “personality” from thread to thread, which is not only pleasant but genuinely helpful for long-term collaboration. GPT’s constructive tone makes it uniquely suited for sustained work — I can always turn to other tools for harsher critique, but GPT has become my main workspace.

**What I wish I could do:**

- Grant GPT persistent access to a folder (e.g. Dropbox, Google Drive, GitHub repo).
    
- Let GPT automatically read/update files like _Master_Glossary.md_ or _Canon_Abstracts.md_ without me re-uploading every version.
    
- Keep a **running canonical memory** across sessions (so glossary staging and abstracting work seamlessly).
    
- Avoid slowdowns that force me to abandon long-lived threads and retrain the model on my context.
    
- Use GPT as an **ongoing collaborator**, not just a one-off text generator.
    

This would make GPT the perfect partner for projects like mine (structured creative/scientific research) and for many other domains where consistency and versioning matter (legal drafting, scientific collaborations, RPG design, curriculum development, etc.).

I’m sharing this because I think my workflow is a strong exemplar of what “power users” need: continuity, consistency, and file-level integration. The current workarounds show GPT is already close to this role — it just needs better tooling to “live” in a project space.

Thanks for all the work you’re doing. And as a small meta note: this email itself was co-authored with GPT, which I think nicely demonstrates the potential I’m describing.

Sincerely,  
[Your Name]